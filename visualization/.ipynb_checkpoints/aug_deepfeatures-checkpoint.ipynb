{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import svm\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import config\n",
    "import util\n",
    "\n",
    "fold_count = 1\n",
    "\n",
    "# Save deep features CNN for svm classification\n",
    "def save_bottlebeck_features(X_train, X_test, y_train, y_test, pretrained_weights):\n",
    "    model = util.load_svm_alex_model(nb_class=config.nb_class, weights_path=pretrained_weights)\n",
    "    \n",
    "    datagen = ImageDataGenerator(rotation_range=40,\n",
    "                             width_shift_range=0.3,\n",
    "                             height_shift_range=0.3,\n",
    "                             horizontal_flip=True,\n",
    "                             zoom_range = 0.25,\n",
    "                             shear_range = 0.25,\n",
    "                             fill_mode='nearest')\n",
    "\n",
    "    bottleneck_features_train = model.predict_generator(datagen.flow(X_train, y_train, batch_size=32), 10000)\n",
    "    \n",
    "    np.save(open('alex_bottleneck_aug_features_train' + str(fold_count) + '.npy', 'wb'), bottleneck_features_train)\n",
    "\n",
    "    bottleneck_features_validation = model.predict_generator(datagen.flow(X_test, y_test, batch_size=32), 10000)\n",
    "    np.save(open('alex_bottleneck_aug_features_validation' + str(fold_count) + '.npy', 'wb'), bottleneck_features_validation)\n",
    "    print \"Deep features extracted \", bottleneck_features_train.shape[1:]\n",
    "\n",
    "def train_svm(y_train, y_test):\n",
    "    X_train = np.load(open('alex_bottleneck_aug_features_train' + str(fold_count) + '.npy' , 'rb'))\n",
    "    X_test = np.load(open('alex_bottleneck_aug_features_validation' + str(fold_count) + '.npy', 'rb'))\n",
    "    \n",
    "    print \"\\nTraining SVM..\"\n",
    "    clf = svm.SVC(kernel='linear', probability=True)\n",
    "    clf.fit(X_train, y_train.ravel())\n",
    "    score = clf.score(X_test, y_test.ravel())\n",
    "    print(\"SVM %s: %.2f%%\" % (\"acc: \", score*100))\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    target_names = ['AisKacang' , 'AngKuKueh' , 'ApamBalik' , 'Asamlaksa' , 'Bahulu' , 'Bakkukteh',\n",
    "     'BananaLeafRice' , 'Bazhang' , 'BeefRendang' , 'BingkaUbi' , 'Buburchacha',\n",
    "     'Buburpedas' , 'Capati' , 'Cendol' , 'ChaiTowKuay' , 'CharKuehTiao' , 'CharSiu',\n",
    "     'CheeCheongFun' , 'ChiliCrab' , 'Chweekueh' , 'ClayPotRice' , 'CucurUdang',\n",
    "     'CurryLaksa' , 'CurryPuff' , 'Dodol' , 'Durian' , 'DurianCrepe' , 'FishHeadCurry',\n",
    "     'Guava' , 'HainaneseChickenRice' , 'HokkienMee' , 'Huatkuih' , 'IkanBakar',\n",
    "     'Kangkung' , 'KayaToast' , 'Keklapis' , 'Ketupat' , 'KuihDadar' , 'KuihLapis',\n",
    "     'KuihSeriMuka' , 'Langsat' , 'Lekor' , 'Lemang' , 'LepatPisang' , 'LorMee',\n",
    "     'Maggi goreng' , 'Mangosteen' , 'MeeGoreng' , 'MeeHoonKueh' , 'MeeHoonSoup',\n",
    "     'MeeJawa' , 'MeeRebus' , 'MeeRojak' , 'MeeSiam' , 'Murtabak' , 'Murukku',\n",
    "     'NasiGorengKampung' , 'NasiImpit' , 'Nasikandar' , 'Nasilemak' , 'Nasipattaya',\n",
    "     'Ondehondeh' , 'Otakotak' , 'OysterOmelette' , 'PanMee' , 'PineappleTart',\n",
    "     'PisangGoreng' , 'Popiah' , 'PrawnMee' , 'Prawnsambal' , 'Puri' , 'PutuMayam',\n",
    "     'PutuPiring' , 'Rambutan' , 'Rojak' , 'RotiCanai' , 'RotiJala' , 'RotiJohn',\n",
    "     'RotiNaan' , 'RotiTissue' , 'SambalPetai' , 'SambalUdang' , 'Satay' , 'Sataycelup',\n",
    "     'SeriMuka' , 'SotoAyam' , 'TandooriChicken' , 'TangYuan' , 'TauFooFah',\n",
    "     'TauhuSumbat' , 'Thosai' , 'TomYumSoup' , 'Wajik' , 'WanTanMee' , 'WaTanHo' , 'Wonton',\n",
    "     'YamCake' , 'YongTauFu' , 'Youtiao' , 'Yusheng']\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    util.plot_confusion_matrix(cm)\n",
    "    #plt.savefig('cm_deep_feaures'+ str(fold_count) +'.png', dpi=300, aspect='auto')\n",
    "    plt.show()\n",
    "    plt.gcf().clear()\n",
    "    f1_score(y_test, y_pred,average=None)\n",
    "    print(classification_report(y_test, y_pred,target_names=target_names))\n",
    "      \n",
    "    #scores = clf.decision_function(X_test)\n",
    "      # Get Top-5\n",
    "    #indices = (-scores).argsort()[:, :5] # take top 5 results\n",
    "    \n",
    "    scores = clf.predict_proba(X_test)\n",
    "    n = 5\n",
    "    indices = np.argsort(scores)[:,:-n-1:-1]\n",
    "    # Get accuracy\n",
    "    top1 = 0.0\n",
    "    top5 = 0.0\n",
    "    correct_predict_top1 = np.zeros((config.nb_class,), dtype=np.int)\n",
    "    correct_predict_top5 = np.zeros((config.nb_class,), dtype=np.int)\n",
    "    \n",
    "    for image_index, index_list in enumerate(indices):\n",
    "        if y_test[image_index] == index_list[0]:\n",
    "            top1 += 1.0\n",
    "        if y_test[image_index] in index_list:\n",
    "            top5 += 1.0\n",
    "            \n",
    "    image_index = None\n",
    "    index_list = None\n",
    "    start_index = 0\n",
    "    end_index = 99\n",
    "    \n",
    "    for class_label in range(0,100):\n",
    "        for image_index in range(start_index,end_index+1):\n",
    "            if y_test[image_index] == indices[image_index][0]:\n",
    "                correct_predict_top1[class_label] += 1\n",
    "            if y_test[image_index] in indices[image_index]:\n",
    "                correct_predict_top5[class_label] += 1\n",
    "        start_index += 100\n",
    "        end_index += 100\n",
    "    \n",
    "    y_pos = np.arange(len(target_names))\n",
    "    performance = correct_predict_top1\n",
    "\n",
    "    rects1 = plt.bar(y_pos, performance)\n",
    "    plt.xticks(y_pos, target_names, rotation='vertical')\n",
    "    plt.ylabel('Total true positive')\n",
    "    plt.title('Total true positive per sample')\n",
    "    \n",
    "    autolabel(rects1)\n",
    "    #plt.savefig('barchart_deep_feaures'+ str(fold_count) +'.png', dpi=300, aspect='auto')\n",
    "    plt.show()\n",
    "    plt.gcf().clear()\n",
    "    \n",
    "    print correct_predict_top1\n",
    "    print correct_predict_top5\n",
    "    \n",
    "    print('Top-1 Accuracy: ' + str(top1 / len(y_test) * 100.0) + '%')\n",
    "    print('Top-5 Accuracy: ' + str(top5 / len(y_test) * 100.0) + '%')\n",
    "\n",
    "    return top1/len(y_test)\n",
    "\n",
    "def autolabel(rects):\n",
    "    # attach some text labels\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        plt.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                '%d' % int(height),\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    total_scores = 0\n",
    "    print \"Loading data..\"\n",
    "    data, labels, lz = util.load_data()\n",
    "    data = data.astype('float32')\n",
    "    data /= 255\n",
    "    lz = np.array(lz)\n",
    "    print lz.shape\n",
    "    print \"Data loaded !\"\n",
    "    \n",
    "    skf = StratifiedKFold(y=lz, n_folds=config.n_folds, shuffle=False)\n",
    "    \n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        print \"Test train Shape: \"\n",
    "        print data[train].shape\n",
    "        print data[test].shape\n",
    "        print (\"Running Fold %d / %d\" % (i+1, config.n_folds))\n",
    "        \n",
    "        save_bottlebeck_features(data[train], data[test],labels[train], labels[test], config.alexnet_weights_path)\n",
    "        scores = train_svm(labels[train], labels[test])\n",
    "        total_scores = total_scores + scores\n",
    "        fold_count = fold_count + 1\n",
    "        \n",
    "    print(\"Average acc : %.2f%%\" % (total_scores/config.n_folds*100))\n",
    "    \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
