{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1060 6GB (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5105)\n",
      "/home/machine/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data..\n",
      "(20000,)\n",
      "Data loaded !\n",
      "Test train Shape: \n",
      "(10000, 3, 227, 227)\n",
      "(10000, 3, 227, 227)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py:1357: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n",
      "/home/machine/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Fold 1 / 2\n",
      "Extracting features..\n",
      "Deep features extracted  (4096,)\n",
      "\n",
      "Training SVM..\n",
      "SVM acc: : 58.30%\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           AisKacang       0.72      0.71      0.71       100\n",
      "           AngKuKueh       0.47      0.41      0.44       100\n",
      "           ApamBalik       0.78      0.74      0.76       100\n",
      "           Asamlaksa       0.41      0.53      0.46       100\n",
      "              Bahulu       0.83      0.87      0.85       100\n",
      "           Bakkukteh       0.70      0.83      0.76       100\n",
      "      BananaLeafRice       0.61      0.56      0.58       100\n",
      "             Bazhang       0.52      0.55      0.54       100\n",
      "         BeefRendang       0.89      0.93      0.91       100\n",
      "           BingkaUbi       0.77      0.85      0.81       100\n",
      "         Buburchacha       0.54      0.61      0.58       100\n",
      "          Buburpedas       0.57      0.67      0.62       100\n",
      "              Capati       0.48      0.60      0.53       100\n",
      "              Cendol       0.48      0.48      0.48       100\n",
      "         ChaiTowKuay       0.85      0.85      0.85       100\n",
      "        CharKuehTiao       0.78      0.76      0.77       100\n",
      "             CharSiu       0.78      0.68      0.73       100\n",
      "       CheeCheongFun       0.76      0.86      0.81       100\n",
      "           ChiliCrab       0.39      0.52      0.45       100\n",
      "           Chweekueh       0.78      0.71      0.74       100\n",
      "         ClayPotRice       0.44      0.46      0.45       100\n",
      "          CucurUdang       0.51      0.37      0.43       100\n",
      "          CurryLaksa       0.29      0.29      0.29       100\n",
      "           CurryPuff       0.43      0.46      0.45       100\n",
      "               Dodol       0.53      0.63      0.57       100\n",
      "              Durian       0.46      0.52      0.49       100\n",
      "         DurianCrepe       0.42      0.47      0.45       100\n",
      "       FishHeadCurry       0.42      0.31      0.36       100\n",
      "               Guava       0.40      0.47      0.43       100\n",
      "HainaneseChickenRice       0.33      0.42      0.37       100\n",
      "          HokkienMee       0.60      0.58      0.59       100\n",
      "            Huatkuih       0.72      0.65      0.68       100\n",
      "           IkanBakar       0.70      0.69      0.70       100\n",
      "            Kangkung       0.73      0.61      0.66       100\n",
      "           KayaToast       0.53      0.48      0.50       100\n",
      "            Keklapis       0.44      0.45      0.45       100\n",
      "             Ketupat       0.52      0.56      0.54       100\n",
      "           KuihDadar       0.48      0.45      0.46       100\n",
      "           KuihLapis       0.79      0.77      0.78       100\n",
      "        KuihSeriMuka       0.43      0.42      0.42       100\n",
      "             Langsat       0.67      0.61      0.64       100\n",
      "               Lekor       0.40      0.37      0.39       100\n",
      "              Lemang       0.69      0.64      0.66       100\n",
      "         LepatPisang       0.41      0.51      0.45       100\n",
      "              LorMee       0.75      0.79      0.77       100\n",
      "        Maggi goreng       0.76      0.75      0.75       100\n",
      "          Mangosteen       0.40      0.48      0.43       100\n",
      "           MeeGoreng       0.47      0.38      0.42       100\n",
      "         MeeHoonKueh       0.81      0.60      0.69       100\n",
      "         MeeHoonSoup       0.39      0.43      0.41       100\n",
      "             MeeJawa       0.76      0.75      0.75       100\n",
      "            MeeRebus       0.48      0.52      0.50       100\n",
      "            MeeRojak       0.56      0.54      0.55       100\n",
      "             MeeSiam       0.69      0.62      0.65       100\n",
      "            Murtabak       0.72      0.60      0.66       100\n",
      "             Murukku       0.61      0.66      0.63       100\n",
      "   NasiGorengKampung       0.59      0.57      0.58       100\n",
      "           NasiImpit       0.68      0.65      0.66       100\n",
      "          Nasikandar       0.74      0.72      0.73       100\n",
      "           Nasilemak       0.30      0.27      0.29       100\n",
      "         Nasipattaya       0.75      0.69      0.72       100\n",
      "          Ondehondeh       0.42      0.42      0.42       100\n",
      "            Otakotak       0.65      0.77      0.70       100\n",
      "      OysterOmelette       0.61      0.51      0.55       100\n",
      "              PanMee       0.60      0.56      0.58       100\n",
      "       PineappleTart       0.40      0.37      0.38       100\n",
      "        PisangGoreng       0.69      0.60      0.64       100\n",
      "              Popiah       0.68      0.75      0.71       100\n",
      "            PrawnMee       0.47      0.55      0.50       100\n",
      "         Prawnsambal       0.57      0.59      0.58       100\n",
      "                Puri       0.66      0.71      0.69       100\n",
      "           PutuMayam       0.47      0.48      0.47       100\n",
      "          PutuPiring       0.27      0.26      0.26       100\n",
      "            Rambutan       0.64      0.57      0.60       100\n",
      "               Rojak       0.88      0.94      0.91       100\n",
      "           RotiCanai       0.53      0.52      0.53       100\n",
      "            RotiJala       0.63      0.48      0.55       100\n",
      "            RotiJohn       0.71      0.71      0.71       100\n",
      "            RotiNaan       0.52      0.65      0.58       100\n",
      "          RotiTissue       0.38      0.27      0.31       100\n",
      "         SambalPetai       0.59      0.65      0.62       100\n",
      "         SambalUdang       0.48      0.42      0.45       100\n",
      "               Satay       0.60      0.59      0.60       100\n",
      "          Sataycelup       0.63      0.67      0.65       100\n",
      "            SeriMuka       0.91      0.92      0.92       100\n",
      "            SotoAyam       0.70      0.65      0.67       100\n",
      "     TandooriChicken       0.49      0.45      0.47       100\n",
      "            TangYuan       0.58      0.54      0.56       100\n",
      "           TauFooFah       0.88      0.85      0.86       100\n",
      "         TauhuSumbat       0.38      0.35      0.37       100\n",
      "              Thosai       0.56      0.60      0.58       100\n",
      "          TomYumSoup       0.79      0.81      0.80       100\n",
      "               Wajik       0.44      0.45      0.44       100\n",
      "           WanTanMee       0.49      0.48      0.49       100\n",
      "             WaTanHo       0.46      0.53      0.50       100\n",
      "              Wonton       0.60      0.54      0.57       100\n",
      "             YamCake       0.37      0.34      0.35       100\n",
      "           YongTauFu       0.77      0.76      0.76       100\n",
      "             Youtiao       0.45      0.35      0.40       100\n",
      "             Yusheng       0.74      0.71      0.72       100\n",
      "\n",
      "         avg / total       0.59      0.58      0.58     10000\n",
      "\n",
      "Top-1 Accuracy: 58.25%\n",
      "Top-5 Accuracy: 85.58%\n",
      "Generating Barchart..\n",
      "[67 37 74 51 85 82 55 56 88 80 58 66 60 48 78 80 68 82 50 72 43 35 29 46 61\n",
      " 50 47 34 47 45 59 65 68 61 47 42 53 43 76 42 59 37 64 56 79 75 50 41 60 45\n",
      " 74 54 55 62 59 62 58 66 68 36 65 49 74 50 60 38 59 73 57 62 72 52 26 57 90\n",
      " 55 50 69 64 28 67 44 56 65 90 67 43 52 82 39 62 81 49 53 56 57 38 74 38 72]\n",
      "[ 78  88  92  84  94 100  85  86  96  94  86  95  84  82  91  94  93  98\n",
      "  78  88  77  69  74  80  85  84  83  61  92  76  81  86  87  86  79  82\n",
      "  82  71  89  78  96  78  91  88  92  92  77  71  85  83  91  88  87  90\n",
      "  88  89  84  92  90  82  87  77  93  89  81  92  81  92  82  84  91  86\n",
      "  65  91  98  92  78  93  84  74  94  92  84  82  95  90  76  80  92  83\n",
      "  92  92  84  83  88  83  82  96  70  88]\n",
      "Test train Shape: \n",
      "(10000, 3, 227, 227)\n",
      "(10000, 3, 227, 227)\n",
      "Running Fold 2 / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/home/machine/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "Unable to open file (Unable to open file: name = '../deep/models/aug_alex_finetune56_finetune5672.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c3022c1f8771>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Running Fold %d / %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0msave_bottleneck67_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malexnet_weights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_svm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mtotal_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_scores\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-c3022c1f8771>\u001b[0m in \u001b[0;36msave_bottleneck67_features\u001b[0;34m(X_train, X_test, y_train, y_test, pretrained_weights)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_bottleneck67_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_svm_alex_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"../deep/models/aug_alex_finetune56_finetune567\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_count\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Extracting features..\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mbottleneck_features_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/machine/projects/foodtag/evaluation/util.pyc\u001b[0m in \u001b[0;36mload_svm_alex_model\u001b[0;34m(weights_path, nb_class)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/machine/anaconda2/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   2492\u001b[0m         '''\n\u001b[1;32m   2493\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2494\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2496\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/machine/anaconda2/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/machine/anaconda2/lib/python2.7/site-packages/h5py/_hl/files.pyc\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (-------src-dir-------/h5py/_objects.c:2582)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (-------src-dir-------/h5py/_objects.c:2541)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open (-------src-dir-------/h5py/h5f.c:1816)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Unable to open file (Unable to open file: name = '../deep/models/aug_alex_finetune56_finetune5672.h5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import svm\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import config\n",
    "import util\n",
    "\n",
    "fold_count = 1\n",
    "\n",
    "def save_bottleneck67_features(X_train, X_test, y_train, y_test, pretrained_weights):\n",
    "    model = util.load_svm_alex_model(weights_path=\"../deep/models/aug_alex_finetune56_finetune567\"+ str(fold_count) +\".h5\",nb_class=config.nb_class)\n",
    "    print \"Extracting features..\"\n",
    "    bottleneck_features_train = model.predict(X_train)\n",
    "    np.save(open('alex_bottleneck67_features_train' + str(fold_count) + '.npy', 'wb'), bottleneck_features_train)\n",
    "\n",
    "    bottleneck_features_validation = model.predict(X_test)\n",
    "    np.save(open('alex_bottleneck67_features_validation' + str(fold_count) + '.npy', 'wb'), bottleneck_features_validation)\n",
    "    print \"Deep features extracted \", bottleneck_features_train.shape[1:]\n",
    "                                               \n",
    "def train_svm(y_train, y_test):\n",
    "    X_train = np.load(open('alex_bottleneck67_features_train' + str(fold_count) + '.npy' , 'rb'))\n",
    "    X_test = np.load(open('alex_bottleneck67_features_validation' + str(fold_count) + '.npy', 'rb'))\n",
    "    \n",
    "    print \"\\nTraining SVM..\"\n",
    "    clf = svm.SVC(kernel='linear', probability=True)\n",
    "    clf.fit(X_train, y_train.ravel())\n",
    "    score = clf.score(X_test, y_test.ravel())\n",
    "    print(\"SVM %s: %.2f%%\" % (\"acc: \", score*100))\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    target_names = ['AisKacang' , 'AngKuKueh' , 'ApamBalik' , 'Asamlaksa' , 'Bahulu' , 'Bakkukteh',\n",
    "     'BananaLeafRice' , 'Bazhang' , 'BeefRendang' , 'BingkaUbi' , 'Buburchacha',\n",
    "     'Buburpedas' , 'Capati' , 'Cendol' , 'ChaiTowKuay' , 'CharKuehTiao' , 'CharSiu',\n",
    "     'CheeCheongFun' , 'ChiliCrab' , 'Chweekueh' , 'ClayPotRice' , 'CucurUdang',\n",
    "     'CurryLaksa' , 'CurryPuff' , 'Dodol' , 'Durian' , 'DurianCrepe' , 'FishHeadCurry',\n",
    "     'Guava' , 'HainaneseChickenRice' , 'HokkienMee' , 'Huatkuih' , 'IkanBakar',\n",
    "     'Kangkung' , 'KayaToast' , 'Keklapis' , 'Ketupat' , 'KuihDadar' , 'KuihLapis',\n",
    "     'KuihSeriMuka' , 'Langsat' , 'Lekor' , 'Lemang' , 'LepatPisang' , 'LorMee',\n",
    "     'Maggi goreng' , 'Mangosteen' , 'MeeGoreng' , 'MeeHoonKueh' , 'MeeHoonSoup',\n",
    "     'MeeJawa' , 'MeeRebus' , 'MeeRojak' , 'MeeSiam' , 'Murtabak' , 'Murukku',\n",
    "     'NasiGorengKampung' , 'NasiImpit' , 'Nasikandar' , 'Nasilemak' , 'Nasipattaya',\n",
    "     'Ondehondeh' , 'Otakotak' , 'OysterOmelette' , 'PanMee' , 'PineappleTart',\n",
    "     'PisangGoreng' , 'Popiah' , 'PrawnMee' , 'Prawnsambal' , 'Puri' , 'PutuMayam',\n",
    "     'PutuPiring' , 'Rambutan' , 'Rojak' , 'RotiCanai' , 'RotiJala' , 'RotiJohn',\n",
    "     'RotiNaan' , 'RotiTissue' , 'SambalPetai' , 'SambalUdang' , 'Satay' , 'Sataycelup',\n",
    "     'SeriMuka' , 'SotoAyam' , 'TandooriChicken' , 'TangYuan' , 'TauFooFah',\n",
    "     'TauhuSumbat' , 'Thosai' , 'TomYumSoup' , 'Wajik' , 'WanTanMee' , 'WaTanHo' , 'Wonton',\n",
    "     'YamCake' , 'YongTauFu' , 'Youtiao' , 'Yusheng']\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    util.plot_confusion_matrix(cm)\n",
    "    #plt.savefig('cm_deep_feaures'+ str(fold_count) +'.png', dpi=300, aspect='auto')\n",
    "    plt.show()\n",
    "    plt.gcf().clear()\n",
    "    f1_score(y_test, y_pred,average=None)\n",
    "    print(classification_report(y_test, y_pred,target_names=target_names))\n",
    "      \n",
    "    #scores = clf.decision_function(X_test)\n",
    "      # Get Top-5\n",
    "    #indices = (-scores).argsort()[:, :5] # take top 5 results\n",
    "    \n",
    "    scores = clf.predict_proba(X_test)\n",
    "    n = 5\n",
    "    indices = np.argsort(scores)[:,:-n-1:-1]\n",
    "    # Get accuracy\n",
    "    top1 = 0.0\n",
    "    top5 = 0.0\n",
    "    correct_predict_top1 = np.zeros((config.nb_class,), dtype=np.int)\n",
    "    correct_predict_top5 = np.zeros((config.nb_class,), dtype=np.int)\n",
    "    \n",
    "    for image_index, index_list in enumerate(indices):\n",
    "        if y_test[image_index] == index_list[0]:\n",
    "            top1 += 1.0\n",
    "        if y_test[image_index] in index_list:\n",
    "            top5 += 1.0\n",
    "    \n",
    "    print('Top-1 Accuracy: ' + str(top1 / len(y_test) * 100.0) + '%')\n",
    "    print('Top-5 Accuracy: ' + str(top5 / len(y_test) * 100.0) + '%')\n",
    "    \n",
    "    print \"Generating Barchart..\"\n",
    "    image_index = None\n",
    "    index_list = None\n",
    "    start_index = 0\n",
    "    end_index = 99\n",
    "    \n",
    "    for class_label in range(0,100):\n",
    "        for image_index in range(start_index,end_index+1):\n",
    "            if y_test[image_index] == indices[image_index][0]:\n",
    "                correct_predict_top1[class_label] += 1\n",
    "            if y_test[image_index] in indices[image_index]:\n",
    "                correct_predict_top5[class_label] += 1\n",
    "        start_index += 100\n",
    "        end_index += 100\n",
    "    \n",
    "    y_pos = np.arange(len(target_names))\n",
    "    performance = correct_predict_top1\n",
    "\n",
    "    rects1 = plt.bar(y_pos, performance)\n",
    "    plt.xticks(y_pos, target_names, rotation='vertical')\n",
    "    plt.ylabel('Total true positive')\n",
    "    plt.title('Total true positive per sample')\n",
    "    \n",
    "    autolabel(rects1)\n",
    "    #plt.savefig('barchart_deep_feaures'+ str(fold_count) +'.png', dpi=300, aspect='auto')\n",
    "    plt.show()\n",
    "    plt.gcf().clear()\n",
    "    \n",
    "    print correct_predict_top1\n",
    "    print correct_predict_top5\n",
    "    \n",
    "\n",
    "\n",
    "    return top1/len(y_test)\n",
    "\n",
    "def autolabel(rects):\n",
    "    # attach some text labels\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        plt.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                '%d' % int(height),\n",
    "                ha='center', va='bottom')\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    total_scores = 0\n",
    "    print \"Loading data..\"\n",
    "    data, labels, lz = util.load_data()\n",
    "    data = data.astype('float32')\n",
    "    data /= 255\n",
    "    lz = np.array(lz)\n",
    "    print lz.shape\n",
    "    print \"Data loaded !\"\n",
    "    \n",
    "    skf = StratifiedKFold(y=lz, n_folds=config.n_folds, shuffle=False)\n",
    "    \n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        print \"Test train Shape: \"\n",
    "        print data[train].shape\n",
    "        print data[test].shape\n",
    "        print (\"Running Fold %d / %d\" % (i+1, config.n_folds))\n",
    "        \n",
    "        save_bottleneck67_features(data[train], data[test],labels[train], labels[test], config.alexnet_weights_path)\n",
    "        scores = train_svm(labels[train], labels[test])\n",
    "        total_scores = total_scores + scores\n",
    "        fold_count = fold_count + 1\n",
    "        \n",
    "    print(\"Average acc : %.2f%%\" % (total_scores/config.n_folds*100))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
